{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edgar: Comparative Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from typing import List, Any\n",
    "import logging\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "kit_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "repo_dir = os.path.abspath(os.path.join(kit_dir, \"..\"))\n",
    "\n",
    "sys.path.append(kit_dir)\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "# Langchain imports\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.huggingface import HuggingFaceInstructEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    load_prompt\n",
    ")\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# Llama index imports\n",
    "from llama_index.core import SimpleDirectoryReader, ServiceContext, VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    CompletionResponseGen,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "\n",
    "\n",
    "from utils.model_wrappers.api_gateway import APIGateway\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(os.path.join(repo_dir,'.env'))\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "dir_path = f'{kit_dir}/data/sec-edgar-filings/reports'\n",
    "\n",
    "# Check if the directory exists and create it if it doesn't\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "    print(\"Directory created:\", dir_path)\n",
    "else:\n",
    "    print(\"Directory already exists:\", dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf' -O '{dir_path}/uber_2021.pdf'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf' -O '{dir_path}/lyft_2021.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uber vs Lift 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SambaNovaLLMWrapper(CustomLLM):\n",
    "    context_window: int = 3900\n",
    "    num_output: int = 256\n",
    "    model_name: str = \"llama3-8b\" # expert name\n",
    "    dummy_response: str = \"\"\n",
    "    \n",
    "    def _get_sambanova_llm(self):\n",
    "\n",
    "        # Set gateway\n",
    "        llm = APIGateway.load_llm(\n",
    "            type=\"sncloud\", # sncloud or sambastudio here\n",
    "            streaming=False,\n",
    "            bundle=True,\n",
    "            max_tokens_to_generate=512,\n",
    "            temperature=0.0,\n",
    "            select_expert=self.model_name,\n",
    "        )\n",
    "\n",
    "        return llm\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            context_window=self.context_window,\n",
    "            num_output=self.num_output,\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        llm = self._get_sambanova_llm()\n",
    "        self.dummy_response = llm.invoke(prompt)\n",
    "        return CompletionResponse(text=self.dummy_response)\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> CompletionResponseGen:\n",
    "        llm = self._get_sambanova_llm()\n",
    "        self.dummy_response = llm.invoke(prompt)\n",
    "        response = \"\"\n",
    "        for token in self.dummy_response:\n",
    "            response += token\n",
    "            yield CompletionResponse(text=response, delta=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our LLM\n",
    "Settings.llm = SambaNovaLLMWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embed model\n",
    "Settings.embed_model = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Represent the query for retrieval: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data \n",
    "lyft_docs = SimpleDirectoryReader(\n",
    "    input_files=[os.path.join(kit_dir,\"data/sec-edgar-filings/reports/lyft_2021.pdf\")]\n",
    ").load_data()\n",
    "uber_docs = SimpleDirectoryReader(\n",
    "    input_files=[os.path.join(kit_dir,\"data/sec-edgar-filings/reports/uber_2021.pdf\")]\n",
    ").load_data()\n",
    "\n",
    "## Build indices\n",
    "lyft_index = VectorStoreIndex.from_documents(lyft_docs, show_progress=True)\n",
    "\n",
    "uber_index = VectorStoreIndex.from_documents(uber_docs, show_progress=True)\n",
    "\n",
    "## Build query engines\n",
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate query engine tools\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Instantiate Sub query engine\n",
    "s_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run queries\n",
    "response = s_engine.query(\n",
    "    \"Compare and contrast the customer segments and geographies that grew the fastest\"\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "response = s_engine.query(\n",
    "    \"Compare revenue growth of Uber and Lyft from 2020 to 2021\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uber vs Lift 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_overlap = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uber data\n",
    "loader = PyPDFLoader(os.path.join(kit_dir,\"data/sec-edgar-filings/reports/uber_2021.pdf\"))\n",
    "data = loader.load()\n",
    "for document in data:\n",
    "    document.metadata['company'] = 'Uber'\n",
    "    document.metadata['year'] = 2021\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "uber_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check uber splits\n",
    "uber_splits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lyft data\n",
    "loader = PyPDFLoader(os.path.join(kit_dir,\"data/sec-edgar-filings/reports/lyft_2021.pdf\"))\n",
    "data = loader.load()\n",
    "for document in data:\n",
    "    document.metadata['company'] = 'Lyft'\n",
    "    document.metadata['year'] = 2021\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "lyft_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check lyft splits\n",
    "lyft_splits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [*uber_splits,*lyft_splits]\n",
    "\n",
    "print(f\"{len(uber_splits)} uber split docs\")\n",
    "print(f\"{len(lyft_splits)} lyft split docs\")\n",
    "print(f\"{len(splits)} all docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings and create vector store\n",
    "embedding = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Represent the query for retrieval: \"\n",
    ")\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SambaNovaCloud\n",
    "api_type = \"sncloud\"\n",
    "llm_expert = 'llama3-8b'\n",
    "\n",
    "# Using SambaStudio\n",
    "# api_type = \"sambastudio\"\n",
    "# llm_expert = 'Meta-Llama-3-70B-Instruct-4096'\n",
    "\n",
    "# Set gateway\n",
    "llm = APIGateway.load_llm(\n",
    "    type=\"sncloud\",\n",
    "    streaming=False,\n",
    "    bundle=True,\n",
    "    max_tokens_to_generate=512,\n",
    "    temperature=0.0,\n",
    "    select_expert='llama3-8b',\n",
    ")\n",
    "\n",
    "llm.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Output parser for a list of lines.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        questions = [question.strip() for question in lines if '?' in question]\n",
    "        return list(filter(None, questions))  # Remove empty lines\n",
    "\n",
    "output_parser = LineListOutputParser()\n",
    "\n",
    "# Testing parser\n",
    "parsing = output_parser.parse(\"  1. What are the revenue breakdowns for Document 1?\\n                       2. What are the revenue breakdowns for Document 2?\")\n",
    "parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and Loading a prompt template\n",
    "query_decomposition_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    \n",
    "    template=\"\"\"Given the following complex query, decompose the query into a list of questions directly and concisely.\n",
    "    Complex query: {question}\n",
    "    List of decomposed questions: \"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "query_decomposition_prompt.save(os.path.join(kit_dir,'prompts/edgar_comparative_qna-query_decomposition_prompt.yaml'))\n",
    "query_decomposition_prompt = load_prompt(os.path.join(kit_dir,'prompts/edgar_comparative_qna-query_decomposition_prompt.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a Chain including the parser\n",
    "llm_chain = LLMChain(llm=llm, prompt=query_decomposition_prompt, output_parser=output_parser)\n",
    "llm_chain.invoke(\"What are the key risks mentioned in the risk factors section of both Microsoft and Apple's 10-K reports, and how do they differ in terms of potential impact and mitigation strategies?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Chain and MultiqueryRetriever\n",
    "llm_chain = LLMChain(llm=llm, prompt=query_decomposition_prompt, output_parser=output_parser)\n",
    "\n",
    "multiquery_retriever = MultiQueryRetriever(\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\n",
    "        'k': 3,\n",
    "        'filter': {'$or': [{'company': {'$eq': 'Uber'}}, {'company': {'$eq': 'Lyft'}}]},\n",
    "    }), \n",
    "    llm_chain=llm_chain, \n",
    "    parser_key=\"decomposed_questions\", \n",
    "    verbose = True\n",
    ")  \n",
    "\n",
    "question = \"What are the key risks mentioned in the risk factors section of both Uber and Lyft's 10-K reports, and how do they differ in terms of potential impact and mitigation strategies?\"\n",
    "\n",
    "# Testing multiquery results\n",
    "multiquery_retrieved_docs = multiquery_retriever.get_relevant_documents(\n",
    "    query=question\n",
    ")[:6]\n",
    "multiquery_retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt for answering and summarization\n",
    "summarization_prompt_template = \"\"\"You're a helpful assistant. Follow these rules:\n",
    "1. Use only the information provided in the context section.\n",
    "2. Provide relevant information to answer the question.\n",
    "Write an answer to the following question based on the following context information and metadata:\n",
    "Question:\n",
    "{original_question}\n",
    "Context:\n",
    "{context}\n",
    "Answer: \"\"\"\n",
    "summarization_prompt = PromptTemplate.from_template(summarization_prompt_template)\n",
    "\n",
    "summarization_prompt.save(os.path.join(kit_dir,'prompts/edgar_comparative_qna-answering_and_summarization_prompt.yaml'))\n",
    "summarization_prompt = load_prompt(os.path.join(kit_dir,'prompts/edgar_comparative_qna-answering_and_summarization_prompt.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the retrieved docs to include metadata in page_content\n",
    "docs_for_summary = []\n",
    "for doc in multiquery_retrieved_docs:\n",
    "    metadata_str = \", \".join([f\"{key}: {value}\" for key, value in doc.metadata.items() if key in (\"company\", \"year\", \"page\")])\n",
    "    extended_page_content = f\"Metadata: \\\"{metadata_str}\\\", Information: \\\"{doc.page_content}\\\"\"\n",
    "    extended_doc = Document(page_content=extended_page_content)\n",
    "    docs_for_summary.append(extended_doc)\n",
    "docs_for_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define StuffDocumentsChain for question answering \n",
    "llm_chain = LLMChain(llm=llm, prompt=summarization_prompt)\n",
    "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"context\", verbose=True)\n",
    "\n",
    "response = stuff_chain.invoke({\"input_documents\": docs_for_summary, 'original_question': question})\n",
    "print(response['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other questions to try\n",
    "questions = [\n",
    "    \"What are the revenue breakdowns for Uber and Lyft in their respective 10-K reports, and how do they compare in terms of total revenue and revenue from different segments?\",\n",
    "    \"What are the key risks mentioned in the risk factors section of both Uber and Lyft's 10-K reports, and how do they differ in terms of potential impact and mitigation strategies?\",\n",
    "    \"How do the corporate governance structures of Uber and Lyft, as outlined in their 10-K filings, compare in terms of board composition, executive compensation, and shareholder rights?\",\n",
    "    \"What are the major investments and acquisitions disclosed in the investment section of Uber and Lyft's 10-K reports, and how do they reflect each company's strategic priorities and growth strategies?\",\n",
    "    \"How do the research and development expenditures disclosed in Uber and Lyft's 10-K reports compare in terms of absolute spending and percentage of revenue, and what insights can be drawn regarding their innovation efforts?\",\n",
    "    \"What are the legal proceedings and regulatory issues disclosed in the legal proceedings section of both Uber and Lyft's 10-K filings, and how do they differ in terms of nature, severity, and potential impact on the companies?\",\n",
    "    \"How do the financial performance metrics such as net income, operating margins, and cash flow ratios disclosed in Uber and Lyft's 10-K reports compare, and what factors contribute to any observed differences?\",\n",
    "    \"What are the geographical revenue breakdowns provided in the geographic segments section of both Uber and Lyft's 10-K reports, and how do they reflect each company's international presence and market diversification?\",\n",
    "    \"How do the sustainability initiatives and environmental disclosures in Uber and Lyft's 10-K filings compare, including information on energy consumption, carbon footprint, and supply chain sustainability efforts?\",\n",
    "    \"What are the forward-looking statements and risk factors outlined in the Management's Discussion and Analysis (MD&A) sections of Uber and Lyft's 10-K reports, and how do they reflect each company's outlook, challenges, and opportunities in the market?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgar_venv",
   "language": "python",
   "name": "edgar_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
