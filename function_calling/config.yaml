llm: 
  "api": "sncloud" #  set either sambastudio or sncloud
  "do_sample": False
  "temperature": 0.0
  "max_tokens_to_generate": 1024
  "coe": True #set as true if using Sambastudio CoE endpoint
  "select_expert": "Meta-Llama-3.1-405B-Instruct" #set if using sncloud, SambaStudio CoE llm exper

tools:
    query_db:
      llm: 
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0 
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"
      db:
        "path": "data/chinook.db" 

    translate:
      llm: 
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"

    rag:
      llm:
        "api": "sncloud" #  set either sambastudio or sncloud
        "do_sample": False
        "temperature": 0.0 
        "max_tokens_to_generate": 1024
        "coe": True #set as true if using Sambastudio CoE endpoint
        "select_expert": "llama3-405b" #set if using sncloud, SambaStudio CoE llm expert
        #sncloud CoE expert name -> "llama3-405b"
      embedding_model: 
        "type": "cpu" # set either sambastudio or cpu
        "batch_size": 1 #set depending of your endpoint configuration (1 if CoE embedding expert)
        "coe": True #set true if using Sambastudio embeddings in a CoE endpoint 
        "select_expert": "e5-mistral-7b-instruct" #set if using SambaStudio CoE embedding expert
      vector_db:
        "path": "data/my-vector-db" # path to your previously created chroma vdb
      retrieval:
        "k_retrieved_documents": 3
        "score_treshold": 0.3

prod_mode: False

st_tools: # set which tools to show in the streamlit app set up bar
  "get_time":
    "enabled": True
    "default": True
  "query_db":
    "enabled": True
    "default": True
  "python_repl":
    "enabled": True
    "default": True
  "calculator":
    "enabled": True
    "default": False
  "translate":
    "enabled": True
    "default": False
  "rag":
    "enabled": True
    "default": False

st_preset_queries: 
  "Create a summary table in the db": >
    Create and save a table in the database that will show the top 10 albums with the highest
    sales in 2013 and in the USA. The table fields will be the name of the album, the name of the
    artist, the total amount of sales, and the number of copies sold.
  "Get information of the created summary table": >
    Give me a summary of the 2013 top albums table
  "Create insightful plots of the summary table": >
    Get the information of the 2013 top albums table in the DB, when you get the data then create
    some meaningful plots that summarize the information, and store them in PNG format