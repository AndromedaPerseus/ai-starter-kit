{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling with Llama 3.1: Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we’ll demonstrate how to use function calling with the Llama 3.1 model (70B). We’ll integrate a simple function called calculateTool, which the model will be able to call when appropriate. The function attributes will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install these required dependencies to run this notebook\n",
    "!pip install langchain-community\n",
    "!pip install python-dotenv==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "repo_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(repo_dir)\n",
    "\n",
    "from utils.model_wrappers.langchain_chat_models import ChatSambaNovaCloud\n",
    "\n",
    "# Constants and Configuration\n",
    "load_dotenv(os.path.join(repo_dir, '.env'), override=True)\n",
    "SAMBANOVA_API_KEY = os.getenv(\"SAMBANOVA_API_KEY\")\n",
    "MODEL = \"Meta-Llama-3.1-70B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools definition\n",
    "\n",
    "# get time tool definition\n",
    "@tool\n",
    "def get_time(kind: str = \"both\") -> str:\n",
    "    \"\"\"Returns current date, current time or both.\n",
    "    Args:\n",
    "        kind: date, time or both\n",
    "    \"\"\"\n",
    "    if kind == \"date\":\n",
    "        date = datetime.now().strftime(\"%m/%d/%Y\")\n",
    "        return f\"Current date: {date}\"\n",
    "    elif kind == \"time\":\n",
    "        time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        return f\"Current time: {time}\"\n",
    "    else:\n",
    "        date = datetime.now().strftime(\"%m/%d/%Y\")\n",
    "        time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        return f\"Current date: {date}, Current time: {time}\"\n",
    "    \n",
    "tools= [get_time]\n",
    "\n",
    "# Define tool invocation method\n",
    "def invoke_tools(tool_calls, messages):\n",
    "    available_functions={tool.name:tool for tool in tools}\n",
    "    for tool_call in tool_calls:\n",
    "        selected_tool = available_functions[tool_call[\"name\"]]\n",
    "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "        print(f\"Tool output: {tool_output}\")\n",
    "        messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool calling model\n",
    "\n",
    "llm = ChatSambaNovaCloud(\n",
    "    sambanova_api_key = SAMBANOVA_API_KEY,\n",
    "    model=MODEL,\n",
    "    max_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_k=1,\n",
    "    top_p=0.01\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate model response: [{'name': 'get_time', 'args': {'kind': 'date'}, 'id': 'call_0958a08d37fc449590', 'type': 'tool_call'}]\n",
      "Tool output: Current date: 11/13/2024\n",
      "final response: Two weeks from today would be 11/27/2024.\n"
     ]
    }
   ],
   "source": [
    "# Call the function calling model\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "       content=\"I need to schedule a meeting for two weeks from today. Can you tell me the exact date of the meeting?\"\n",
    "    )\n",
    "]\n",
    "\n",
    "response = llm_with_tools.invoke(messages)\n",
    "while len(response.tool_calls)>0:\n",
    "    print(f\"Intermediate model response: {response.tool_calls}\")\n",
    "    messages.append(response)\n",
    "    messages = invoke_tools(response.tool_calls, messages)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(f\"final response: {response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
