{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring Your Own Checkpoint (BYOC) to SamabaStudio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example checkpoint download from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download, HfApi\n",
    "\n",
    "model_name = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"  # Replace with your desired model\n",
    "\n",
    "target_dir = \"./models\"  \n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "repo_files = HfApi().list_repo_files(model_name)\n",
    "\n",
    "for file_name in repo_files:\n",
    "    hf_hub_download(repo_id=model_name, filename=file_name, cache_dir=target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After download, modify [config.yaml](./config.yaml) file with the snapshot of the model and required parameters\n",
    "\n",
    "check at the `chat_template` key in the [tokenizer_config.json](./models/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/tokenizer_config.json) file inside the model snapshot and modify it to follow a chat jinja template like this:\n",
    "\n",
    "```json\n",
    "  \"chat_template\": \"{% for message in messages %}{% set content = '<|im_start|>' + message['role'] + '\\n' + message['content'] | trim + '<|im_end|>'+'\\n' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}<|im_start|>assistant\\n\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 11:22:21,683 [INFO] Using config file located in ./config.yaml\n",
      "2024-11-19 11:22:21,686 [INFO] Using variables from Snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "from src.snsdk_byoc_wrapper import BYOC\n",
    "byoc = BYOC(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your jinja chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 11:03:09,282 [INFO] Raw chat template for checkpoint in ./models/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725:\n",
      "{% for message in messages %}{% set content = '<|im_start|>' + message['role'] + '\n",
      "' + message['content'] | trim + '<|im_end|>'+'\n",
      "' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}<|im_start|>assistant\n",
      "\n",
      "\n",
      "2024-11-19 11:03:09,289 [INFO] Rendered template with input test messages:\n",
      "\n",
      "<|begin_of_text|><|im_start|>system\n",
      "This is a system prompt.<|im_end|>\n",
      "<|im_start|>user\n",
      "This is a user prompt.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "This is a response from the assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "This is an user follow up<|im_end|>\n",
      "<|im_start|>assistant\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"This is a system prompt.\"},\n",
    "    {\"role\": \"user\", \"content\": \"This is a user prompt.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"This is a response from the assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"This is an user follow up\"}\n",
    "    ]\n",
    "byoc.check_chat_templates(test_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set BYOC object with checkpoints to upload config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get params from checkpoints paths set in [config.yaml](./config.yaml) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 14:45:09,453 [INFO] Params for checkpoint in ./models/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725:\n",
      "[{'model_arch': 'llama', 'seq_length': 8192, 'vocab_size': 128256}]\n",
      "2024-11-18 14:45:09,455 [INFO] config updated with checkpoints parameters\n",
      "2024-11-18 14:45:09,457 [INFO] config file updated with checkpoints parameters\n"
     ]
    }
   ],
   "source": [
    "byoc.find_config_params(update_config_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find suitable SambaStudio apps for your checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 20:15:00,196 [INFO] Checkpoint HermesProInstructV10 suitable apps:\n",
      "{'id': '61fa0993-04a2-42ca-9db1-1eff693ea978', 'name': 'Samba1 Llama3 Experts'}\n",
      "{'id': 'ad39e323-9878-4914-8e29-82c9f2939475', 'name': 'Llama 3'}\n"
     ]
    }
   ],
   "source": [
    "byoc.get_suitable_apps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set in the `app_id` key of your checkpoint in the [config.yaml](./config.yaml) file the desired app_id of your checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the checkpoints in your [config.yaml](./config.yaml) file to SambaStudio (this could take from minutes to hours depending on the size of your checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 11:22:25,609 [INFO] Using config file located in ./config.yaml\n",
      "2024-11-19 11:22:25,610 [INFO] Using variables from Snapi config to set up Snsdk.\n"
     ]
    }
   ],
   "source": [
    "#load the updated config.yaml file including app ids and model params\n",
    "byoc = BYOC(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byoc.upload_checkpoints()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the status of the checkpoints after the upload process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:01:49,150 [INFO] model HermesProInstructV10 status: \n",
      " {'model_id': '0402d3fd-3ad1-4368-837b-5323bcac842c', 'status': 'Available', 'progress': 100, 'stage': 'convert', 'status_code': 200}\n"
     ]
    }
   ],
   "source": [
    "byoc.get_checkpoints_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a bundle model including uploaded and existing checkpoints in sambastudio setting `composite_model` params in [config.yaml](./config.yaml) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:01:51,024 [INFO] Model with name 'TestByocCoE' found with id 6aada915-b864-489f-8663-22331ea5d457\n",
      "2024-11-18 22:01:51,024 [INFO] Model with name 'TestByocCoE' not created it already exist with id 6aada915-b864-489f-8663-22331ea5d457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6aada915-b864-489f-8663-22331ea5d457'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byoc.create_composite_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can deploy the bundle model, setting `deployement` params in [config.yaml](./config.yaml) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:01:55,219 [INFO] Project with name 'example-byoc-project' found with id 05872601-c99b-4ece-9ccf-381821a1a9a5\n",
      "2024-11-18 22:01:55,220 [INFO] Project with name 'example-byoc-project' already exists with id '05872601-c99b-4ece-9ccf-381821a1a9a5', using it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'05872601-c99b-4ece-9ccf-381821a1a9a5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create project\n",
    "byoc.create_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 22:01:56,619 [INFO] Project with name 'example-byoc-project' found with id 05872601-c99b-4ece-9ccf-381821a1a9a5\n",
      "2024-11-18 22:01:56,869 [INFO] Model with name 'TestByocCoE' found with id 6aada915-b864-489f-8663-22331ea5d457\n",
      "2024-11-18 22:01:57,153 [INFO] Endpoint with name 'test-endpoint-byoc' not found in project '05872601-c99b-4ece-9ccf-381821a1a9a5'\n",
      "2024-11-18 22:01:57,468 [INFO] Endpoint 'test-endpoint-byoc' created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8839d682-278b-4d09-8eaf-f93cdf5963aa'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deploy your model in an endpoint\n",
    "byoc.create_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get endpoint details\n",
    "byoc.get_endpoint_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 09:31:36,059 [INFO] Project with name 'example-byoc-project' found with id 9d17a0b5-b0f1-478c-9edb-51e8c93fd492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatSambaStudio\n",
    "\n",
    "endpoint_details = byoc.get_endpoint_details()\n",
    "endpoint_url = endpoint_details[\"langchain_wrapper_env\"].get(\"SAMBASTUDIO_URL\")\n",
    "endpoint_api_key = endpoint_details[\"langchain_wrapper_env\"].get(\"SAMBASTUDIO_API_KEY\")\n",
    "\n",
    "llm = ChatSambaStudio(\n",
    "    sambastudio_url=endpoint_url,\n",
    "    sambastudio_api_key=endpoint_api_key,\n",
    "    do_sample= True, \n",
    "    temperature= 0.01,\n",
    "    max_tokens= 512,\n",
    "    top_p= 1.0,\n",
    "    top_k= 50,\n",
    "    process_prompt=False,\n",
    "    model= \"HermesProInstructV10\"\n",
    ")\n",
    "print(llm.invoke(\"tell me a joke\").content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
