embedding_model: 
    "type": "cpu"
    "batch_size": 1
    "coe": True
    "select_expert": "e5-mistral-7b-instruct"

bad_format_chat_model:
    - type: "sncloud"
      model: 1
      max_tokens: 1024
      temperature: 0.0
      streaming: False

    - type: "sncloud"
      model: "foo"
      max_tokens: 1024
      temperature: 0.0
      streaming: "string"
    
    - type: "sncloud"
      model: "foo"
      max_tokens: "one"
      temperature: 0.0
      streaming: False

    - type: "sncloud"
      model: "foo"
      max_tokens: 1024
      temperature: "string"
      streaming: False

    - type: "sncloud"
      model: "foo"
      max_tokens: 1024
      temperature: 0.0
      streaming: False
      stream_options: "string"

sn_chat_model:
    "type": "sncloud"
    "model": "llama3-8b"
    "streaming": False
    "max_tokens": 1024
    "temperature": 0.7
    "top_k": 1
    "top_p": 0.01
    "stream_options" : 
        "include_usage": True

sambastudio_chat_model:
    "type": "sambastudio"
    "model": "Meta-Llama-3-70B-Instruct-4096"
    "temperature": 0.0
    "do_sample": False
    "max_tokens": 1200
